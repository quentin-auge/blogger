{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.model import fit\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit language model on Wordpress data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, bptt = 64, 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download fr\n",
    "\n",
    "my_tok = spacy.load('fr')\n",
    "\n",
    "def my_spacy_tok(x):\n",
    "    return [tok.text for tok in my_tok.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/txt/wordpress/'\n",
    "TEXT = data.Field(lower=True, tokenize=my_spacy_tok)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, train='.', validation='.', test='.',\n",
    "                                       bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 4002, 1, 558973)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200\n",
    "nh = 500\n",
    "nl = 3\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl, dropout=0.05, dropouth=0.1, dropouti=0.05, dropoute=0.02, wdrop=0.2)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2b278455754564a4cb3115282eb653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      5.41836    5.1515    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4773d29cfcd94b68b5d7144a0af2798c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      4.964747   4.861962  \n",
      "    1      4.710859   4.511409  \n",
      "    2      4.499228   4.398448  \n",
      "    3      4.389906   4.205618  \n",
      "    4      4.214793   4.045292  \n",
      "    5      4.100974   3.948904  \n",
      "    6      4.032428   3.925189  \n",
      "    7      4.065681   3.863705  \n",
      "    8      3.962731   3.748533  \n",
      "    9      3.858471   3.633356  \n",
      "    10     3.764991   3.536353  \n",
      "    11     3.685439   3.447273  \n",
      "    12     3.616239   3.393011  \n",
      "    13     3.578113   3.365949  \n",
      "    14     3.576423   3.36475   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5166e7217654a529c6a0665282f89a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      3.621457   3.424829  \n",
      "    1      3.614206   3.343866  \n",
      "    2      3.550171   3.273521  \n",
      "    3      3.47219    3.167678  \n",
      "    4      3.415134   3.09017   \n",
      "    5      3.342923   3.012518  \n",
      "    6      3.283233   2.959568  \n",
      "    7      3.243617   2.922631  \n",
      "    8      3.208909   2.923379  \n",
      "    9      3.20387    2.886638  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c072de54084361a2a83760580900db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      3.254793   2.883765  \n",
      "    1      3.270128   2.881448  \n",
      "    2      3.239029   2.847525  \n",
      "    3      3.232687   2.858032  \n",
      "    4      3.206249   2.821148  \n",
      "    5      3.171746   2.772858  \n",
      "    6      3.147078   2.755853  \n",
      "    7      3.194739   2.779003  \n",
      "    8      3.170617   2.7595    \n",
      "    9      3.157458   2.715929  \n",
      "    10     3.121693   2.688937  \n",
      "    11     3.096725   2.668138  \n",
      "    12     3.077755   2.633148  \n",
      "    13     3.077113   2.623319  \n",
      "    14     3.077111   2.6103    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(1e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e660f7ecb43443f4b8832d06c11fb71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      3.110921   2.705874  \n",
      "    1      3.108543   2.645146  \n",
      "    2      3.063471   2.617466  \n",
      "    3      3.111695   2.619941  \n",
      "    4      3.034176   2.557742  \n",
      "    5      3.015316   2.519851  \n",
      "    6      2.985358   2.496241  \n",
      "    7      2.965874   2.478436  \n",
      "    8      2.943421   2.474756  \n",
      "    9      2.976183   2.489776  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(1e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show most common predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_str(s): return TEXT.preprocess(TEXT.tokenize(s))\n",
    "def num_str(s): return TEXT.numericalize([proc_str(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"j'aime\"\n",
    "t = num_str(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le', 'la', 'les', 'l’', 'se', 'vous', 'voyager', 'faire', 'pouvoir', 'leur']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(m, s, l=100):\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    t = num_str(s)\n",
    "    m[0].bs=1\n",
    "    m.eval()\n",
    "    m.reset()\n",
    "    res,*_ = m(t)\n",
    "    result += s + ' '\n",
    "\n",
    "    for i in range(l):\n",
    "        n = res[-1].topk(2)[1]\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        word = TEXT.vocab.itos[n.data[0]]\n",
    "        result += word + ' '\n",
    "        if word=='<eos>': break\n",
    "        res,*_ = m(n[0].unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "    m[0].bs=bs\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je suis obligé de me faire plaisir . je ne sais pas si ce voyage est une ville très touristique , très grande , c’ est aussi la grande ville qui m’ a fait pour se faire inviter . je suis bien content de me voir seul et de me faire inviter à dormir chez l’ habitant . je me suis aussi fait un peu de temps pour moi , et pour un autre voyage en australie . je n’ ai pas eu de problème à me faire plaisir . je ne sais pas si ce voyage est une expérience très touristique '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model(m, 'je suis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune on blogger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/txt/blogger'\n",
    "md2 = LanguageModelData.from_text_files(PATH, TEXT, train='.', validation='.', test='.',\n",
    "                                       bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4002, 1, 95914)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md2.trn_dl), md2.nt, len(md2.trn_ds), len(md2.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200\n",
    "nh = 500\n",
    "nl = 3\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner2 = md2.get_model(opt_fn, em_sz, nh, nl, dropout=0.05, dropouth=0.1, dropouti=0.05, dropoute=0.02, wdrop=0.2)\n",
    "learner2.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner2.clip = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa7a2524bf14f449505a7f7144c1610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      4.07943    3.612095  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner2.fit(3e-3, 1, wds=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b4f78145b6410abf2dbf5a0f4abd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      3.729076   3.4321    \n",
      "    1      3.649061   3.236375  \n",
      "    2      3.53968    3.166946  \n",
      "    3      3.483248   3.033893  \n",
      "    4      3.402295   2.859933  \n",
      "    5      3.293501   2.742957  \n",
      "    6      3.212594   2.733846  \n",
      "    7      3.17222    2.634837  \n",
      "    8      3.112819   2.48527   \n",
      "    9      3.032762   2.337774  \n",
      "    10     2.938747   2.240985  \n",
      "    11     2.830832   2.172124  \n",
      "    12     2.736191   2.025528  \n",
      "    13     2.659064   1.991474  \n",
      "    14     2.600195   1.999561  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner2.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15245262bb78419d8334a115a910504d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      2.508398   2.028785  \n",
      "    1      2.506911   1.910381  \n",
      "    2      2.477282   1.858803  \n",
      "    3      2.442942   1.696492  \n",
      "    4      2.39218    1.615291  \n",
      "    5      2.311126   1.52568   \n",
      "    6      2.239762   1.448574  \n",
      "    7      2.192392   1.445718  \n",
      "    8      2.15074    1.409442  \n",
      "    9      2.128195   1.430044  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner2.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d89465eb5f4e6f9c4cb5bf3cf0dac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      2.045861   1.391264  \n",
      "    1      2.07245    1.361346  \n",
      "    2      2.109661   1.374343  \n",
      "    3      2.065975   1.356039  \n",
      "    4      2.026473   1.310358  \n",
      "    5      2.025779   1.267039  \n",
      "    6      1.988473   1.310442  \n",
      "    7      2.001189   1.421678  \n",
      "    8      1.987376   1.272208  \n",
      "    9      1.94994    1.184513  \n",
      "    10     1.92364    1.159139  \n",
      "    11     1.913576   1.145634  \n",
      "    12     1.931912   1.139126  \n",
      "    13     1.928751   1.177401  \n",
      "    14     1.901622   1.257719  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner2.fit(1e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f2621038154b99873a706a8790c7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      1.806324   1.147617  \n",
      "    1      1.825615   1.086717  \n",
      "    2      1.792029   1.049193  \n",
      "    3      1.825028   1.042164  \n",
      "    4      1.783125   1.027698  \n",
      "    5      1.786378   0.990423  \n",
      "    6      1.781774   1.047837  \n",
      "    7      1.764112   1.0085    \n",
      "    8      1.72583    1.004652  \n",
      "    9      1.732903   0.980324  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner2.fit(1e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe36e7ebb8141cea1966aacef452732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      1.847859   1.060709  \n",
      "    1      1.813359   1.026883  \n",
      "    2      1.778089   0.948474  \n",
      "    3      1.824945   1.080708  \n",
      "    4      1.800656   0.993749  \n",
      "    5      1.737481   0.902956  \n",
      "    6      1.709092   0.892642  \n",
      "    7      1.695567   0.864817  \n",
      "    8      1.700057   0.84268   \n",
      "    9      1.672589   0.770739  \n",
      "    10     1.623281   0.716308  \n",
      "    11     1.584262   0.687014  \n",
      "    12     1.523147   0.624581  \n",
      "    13     1.483324   0.658361  \n",
      "    14     1.474085   0.621477  \n",
      "    15     1.520616   0.714385  \n",
      "    16     1.520002   0.642848  \n",
      "    17     1.515244   0.60481   \n",
      "    18     1.472622   0.54816   \n",
      "    19     1.449795   0.688151  \n",
      "    20     1.420494   0.504746  \n",
      "    21     1.417902   0.512269  \n",
      "    22     1.363959   0.54308   \n",
      "    23     1.324987   0.447386  \n",
      "    24     1.280399   0.387428  \n",
      "    25     1.230288   0.366208  \n",
      "    26     1.175008   0.361138  \n",
      "    27     1.143298   0.340434  \n",
      "    28     1.104044   0.444046  \n",
      "    29     1.090434   0.36496   \n",
      "    30     1.060853   0.355106  \n",
      "    31     1.118066   0.386127  \n",
      "    32     1.140418   0.368322  \n",
      "    33     1.182965   0.372192  \n",
      "    34     1.199301   0.393481  \n",
      "    35     1.161815   0.313019  \n",
      "    36     1.130646   0.291827  \n",
      "    37     1.112785   0.286583  \n",
      "    38     1.126401   0.312675  \n",
      "    39     1.07705    0.349924  \n",
      "    40     1.084226   0.332778  \n",
      "    41     1.042186   0.299573  \n",
      "    42     1.004829   0.231794  \n",
      "    43     1.011692   0.213601  \n",
      "    44     1.004994   0.173315  \n",
      "    45     0.968305   0.207611  \n",
      "    46     0.967713   0.285922  \n",
      "    47     0.93275    0.210089  \n",
      "    48     0.868094   0.13737   \n",
      "    49     0.851825   0.216484  \n",
      "    50     0.830233   0.125968  \n",
      "    51     0.810974   0.199133  \n",
      "    52     0.806305   0.112414  \n",
      "    53     0.81732    0.236855  \n",
      "    54     0.825024   0.137007  \n",
      "    55     0.794917   0.137206  \n",
      "    56     0.779853   0.150763  \n",
      "    57     0.770704   0.133397  \n",
      "    58     0.760285   0.10101   \n",
      "    59     0.72433    0.114146  \n",
      "    60     0.712803   0.099623  \n",
      "    61     0.705845   0.102617  \n",
      "    62     0.732909   0.129345  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner2.fit(3e-3, 6, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = learner2.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je suis fatigué du stop qui ne marche pas , et je dois marcher pour la nuit . de toute façon , je vais en profiter pour faire un petit tour de terrain de foot très haut , mais vu que le paysage est en train de dormir dans le désert . je sais bien que le terrain est à peine pour sortir de la paz , mais je suis dans le vent . la douleur se termine plutôt . je suis un peu trop faible pour que ça soit normal , et je me fais embarquer en chemin par un groupe '"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model(m2, 'je suis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = sample_model(m2, 'je suis', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('data/sampled.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle extra spaces\n",
    "txt = txt.replace('\\xa0', ' ')  # non-breaking spaces\n",
    "txt = txt.replace(' ,', ',')\n",
    "txt = txt.replace(' ,', ',')\n",
    "txt = txt.replace(' :', ':')\n",
    "txt = txt.replace(' ;', ';')\n",
    "txt = txt.replace(' / ', '/')\n",
    "txt = txt.replace(\"' \", \"'\")\n",
    "txt = txt.replace('( ', '(')\n",
    "txt = txt.replace(' )', ')')\n",
    "for _ in range(3):\n",
    "    txt = txt.replace('. .', '..')\n",
    "    txt = txt.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize letters after '.'\n",
    "txt = '. '.join(s.strip().capitalize() for s in txt.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip text so that it ends with '.'\n",
    "last_full_stop_idx = txt.rfind('.')\n",
    "txt = txt[:last_full_stop_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into paragraphs\n",
    "N_SENTENCES = 20\n",
    "sentences = [s.strip() for s in txt.split('.')]\n",
    "txt = '\\n\\n'.join('. '.join(sentences[i:i + N_SENTENCES]) + '.' for i in range(0, len(sentences), N_SENTENCES))\n",
    "txt = txt.replace('. .', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis fatigué du stop qui ne marche pas, et je dois marcher pour la nuit. De toute façon, je vais en profiter pour faire un petit tour de terrain de foot très haut, mais vu que le paysage est en train de dormir dans le désert. Je sais bien que le terrain est à peine pour sortir de la paz, mais je suis dans le vent. La douleur se termine plutôt. Je suis un peu trop faible pour que ça soit normal, et je me fais embarquer en chemin par un groupe de français qui y va en pente. Je ne peux pas dire que sa mort me touche pas, après avoir lu tant de ses amis. Elle est désormais dans le pays, mais pourtant, ça sera à la douane. Bon, maintenant, les choses ne se termine jamais comme prévu, et à un moment, il est possible que les moustiques sont très sympathiques. Ils sont en train de faire du stop tout juste la douane pour ne plus faire par la fenêtre. En fait, elle ne se termine pas, et je les fais à un moment, et je demande au bout de 500 mètres. Je ne compte que trois de leurs enfants sur cinq. Ils sont déjà sur le chemin. Deux heures plus tard, je parcours 50 kilomètres de bas en pente, en me demandant qui va venir me faire payer 50 mètres en direction de la paz. Il y a une station essence et je demande que ça ne va pas être possible. Puis son mari se vide et je leur dit de me laisser là. Et puis, si ils me disent que je ne peux pas dormir, mais tout comme le bus, il me répond. Il me faut un panneau. Après une heure et une heure et une heure et une heure et une heure et un camion à 50 km/h en me faisant des signes de la main, je me fais embarquer par un camion pour 120 km). Vu que je suis en train de faire des informations sur internet, je me fais embarquer par un bus pour un village avec un vieux monsieur à qui je demande si il a eu le sens de cette tente au moment de passer en stop. Il me faut un panneau.\n",
      "\n",
      "Après une intense de réflexion pendant laquelle il me reste de la ville, je suis toujours en mesure de me rendre dans la jungle (sud - est), ni sur la côte pacifiqu\n"
     ]
    }
   ],
   "source": [
    "print(txt[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soleil ne marche, et je me fais embarquer par un bus. D'ailleurs, il est temps de faire sécher les vêtements et les vêtements dans les jambes. Je remercie mes conducteurs qui en passent. Je ne comprends pas trop où sont passés les artistes de rue argentins si présents à bord. Il y a bien un moment où il faut retourner à la maison, et vu que je suis malade. Je me fais embarquer par 2 taxis de suite (même si ça peut fait 3 jours, il est temps de mettre un peu de temps pour traverser de la colombie. Et, pour les deux raisons que voici, ce ne sont pas des vacances, merci. Le lendemain, je retrouve mes affaires sur la route, et je vais voir le conducteur du bus. Le conducteur me demande de venir voir si je fais un signe de tour. Il peut se rendre finalement, vu que je ne suis pas un problème de route. Je le remercie, et je lui demande si il a une idée d'où je cherche un endroit pour planter la tente. D'ailleurs il fait nuit et il va falloir y penser, mais ma bouteille d'eau est vide et je suis de nouveau en dehors. Quitter la route de la paz, et je prends la direction de nul part. Je me fais embarquer par 2 taxis de suite (même si ça peut prendre 3 jours de marche), et en profite pour aller visiter le site de (non merci), non sans avoir pris la peine de laisser en cadeau à mon sac en que je suis arrivé à la maison. Non. Je sais bien que le type à la sortie ne peut pas être très loin, étant donné que le salaire est de 30 °c pour une nuit, mais à un moment, on est quand même des touristes. Et puis, une fois le soleil, une voiture passe, et un camion pour sortir du port qui indique être pris par un camion - van qui commence à devenir aride (un type à 10 heures de marche), et je dois marcher. Pas de route, mais ce qui est plus en train de faire des rencontres similaires.\n",
      "\n",
      "La pluie est toujours trop vide, et je suis de plus en plus sec. Et puis, une fois le soleil, une voiture passe, et leur explique mon projet de dormir dehors. Après un temps de réflexion, la route est vide.\n"
     ]
    }
   ],
   "source": [
    "print(txt[-2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/generated/words_sample.txt', 'w') as f:\n",
    "    f.write(txt + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blogger",
   "language": "python",
   "name": "blogger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
